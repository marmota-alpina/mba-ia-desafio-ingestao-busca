# Desafio MBA Engenharia de Software com IA - Full Cycle

## IngestÃ£o e Busca SemÃ¢ntica com LangChain e PostgreSQL + pgVector

Sistema RAG (Retrieval-Augmented Generation) para ingestÃ£o de documentos PDF e busca semÃ¢ntica com respostas baseadas exclusivamente no conteÃºdo do documento.

---

## ğŸ¯ Objetivo

Este projeto implementa:

1. **IngestÃ£o**: LÃª um arquivo PDF e armazena suas informaÃ§Ãµes em um banco de dados PostgreSQL com extensÃ£o pgVector
2. **Busca**: Permite que o usuÃ¡rio faÃ§a perguntas via linha de comando (CLI) e receba respostas baseadas **apenas** no conteÃºdo do PDF

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **Linguagem**: Python 3.13+
- **Framework**: LangChain
- **Banco de Dados**: PostgreSQL 17 + pgVector
- **ExecuÃ§Ã£o**: Docker & Docker Compose
- **LLM Provider**: Google Gemini (alternativa: OpenAI)

---

## ğŸ“‹ PrÃ©-requisitos

- Python 3.13 ou superior
- Docker e Docker Compose
- API Key do Google Gemini ou OpenAI

---

## ğŸš€ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
git clone <seu-repositorio>
cd mba-ia-desafio-ingestao-busca
```

### 2. Configure o ambiente virtual Python

```bash
python3 -m venv .venv
source .venv/bin/activate  # No Windows: .venv\Scripts\activate
```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Configure as variÃ¡veis de ambiente

Copie o arquivo de exemplo:

```bash
cp .env.example .env
```

Edite o arquivo `.env` e configure sua API key:

**Para Google Gemini (Recomendado para este projeto):**
```bash
GOOGLE_API_KEY=sua_chave_aqui
GOOGLE_EMBEDDING_MODEL=models/text-embedding-004
```

**Ou para OpenAI:**
```bash
OPENAI_API_KEY=sk-sua_chave_aqui
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
```

As demais variÃ¡veis jÃ¡ estÃ£o prÃ©-configuradas:
- `DATABASE_URL=postgresql+psycopg://postgres:postgres@localhost:5432/rag`
- `PG_VECTOR_COLLECTION_NAME=pdf_embeddings`
- `PDF_PATH=./document.pdf`

### 5. Inicie o banco de dados PostgreSQL

```bash
docker compose up -d
```

Aguarde alguns segundos para o banco inicializar. VocÃª pode verificar o status com:

```bash
docker compose ps
```

---

## ğŸ“– Como Executar

### Passo 1: Ingerir o PDF

Execute o script de ingestÃ£o para carregar o documento no banco de dados:

```bash
python src/ingest.py
```

**SaÃ­da esperada:**
```
Carregando PDF: ./document.pdf
âœ“ 34 pÃ¡gina(s) carregada(s)

Dividindo documento em chunks...
âœ“ 67 chunk(s) criado(s)

Obtendo modelo de embeddings...
Usando Google Generative AI Embeddings...

Armazenando chunks no banco de dados (collection: pdf_embeddings)...

âœ… IngestÃ£o concluÃ­da com sucesso!
   - 67 chunks armazenados
   - Collection: pdf_embeddings
   - Banco de dados: localhost:5432/rag
```

### Passo 2: Executar o Chat

Inicie a interface de chat interativa:

```bash
python src/chat.py
```

**Exemplo de uso:**

```
============================================================
  RAG Chat - Pergunte sobre o documento PDF
============================================================

Digite 'sair', 'exit' ou 'quit' para encerrar
Digite 'limpar' ou 'clear' para limpar a tela

âœ“ Sistema iniciado com sucesso!

PERGUNTA: Qual o faturamento da Alfa Energia S.A.?

ğŸ” Buscando informaÃ§Ãµes...

RESPOSTA: R$ 722.875.391,46

------------------------------------------------------------

PERGUNTA: Quando a Alfa AgronegÃ³cio IndÃºstria foi fundada?

ğŸ” Buscando informaÃ§Ãµes...

RESPOSTA: 1931

------------------------------------------------------------

PERGUNTA: Qual Ã© a capital da FranÃ§a?

ğŸ” Buscando informaÃ§Ãµes...

RESPOSTA: NÃ£o tenho informaÃ§Ãµes necessÃ¡rias para responder sua pergunta.

------------------------------------------------------------
```

---

## âœ… ValidaÃ§Ã£o do Sistema

O sistema **responde apenas com base no contexto** do PDF. Perguntas fora do escopo retornam a mensagem padrÃ£o:

### âœ… Perguntas dentro do contexto (respondidas):
- "Qual o faturamento da Alfa Energia S.A.?" â†’ **R$ 722.875.391,46**
- "Quando a Alfa AgronegÃ³cio IndÃºstria foi fundada?" â†’ **1931**

### âŒ Perguntas fora do contexto (recusadas):
- "Qual Ã© a capital da FranÃ§a?" â†’ **NÃ£o tenho informaÃ§Ãµes necessÃ¡rias para responder sua pergunta.**
- "Quantos clientes temos em 2024?" â†’ **NÃ£o tenho informaÃ§Ãµes necessÃ¡rias para responder sua pergunta.**
- "VocÃª acha isso bom ou ruim?" â†’ **NÃ£o tenho informaÃ§Ãµes necessÃ¡rias para responder sua pergunta.**

---

## ğŸ”§ Comandos Ãšteis

### Parar o banco de dados
```bash
docker compose down
```

### Parar e remover volumes (limpa dados)
```bash
docker compose down -v
```

### Verificar logs do PostgreSQL
```bash
docker compose logs postgres
```

### Re-ingestÃ£o (limpar e recarregar)
```bash
python src/ingest.py
```
O script automaticamente remove a collection anterior antes de criar uma nova.

### Teste rÃ¡pido sem interface interativa
```bash
python src/search.py "Sua pergunta aqui"
```

---

## ğŸ“ Estrutura do Projeto

```
â”œâ”€â”€ docker-compose.yml          # ConfiguraÃ§Ã£o PostgreSQL + pgVector
â”œâ”€â”€ requirements.txt            # DependÃªncias Python
â”œâ”€â”€ .env.example                # Template de variÃ¡veis de ambiente
â”œâ”€â”€ .env                        # VariÃ¡veis de ambiente (nÃ£o commitado)
â”œâ”€â”€ document.pdf                # PDF para ingestÃ£o
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest.py              # Script de ingestÃ£o do PDF
â”‚   â”œâ”€â”€ search.py              # MÃ³dulo de busca semÃ¢ntica
â”‚   â””â”€â”€ chat.py                # Interface CLI para chat
â”œâ”€â”€ CLAUDE.md                   # DocumentaÃ§Ã£o para Claude Code
â”œâ”€â”€ PLANO_EXECUCAO.md          # Plano detalhado de desenvolvimento
â””â”€â”€ README.md                   # Este arquivo
```

---

## ğŸ§ª Detalhes TÃ©cnicos

### IngestÃ£o (src/ingest.py)
- Carrega PDF usando `PyPDFLoader`
- Divide em chunks de **1000 caracteres** com **overlap de 150**
- Gera embeddings usando modelo configurado
- Armazena vetores no PostgreSQL com pgVector

### Busca (src/search.py)
- Conecta ao vectorstore existente
- Busca os **top 10 documentos** mais relevantes (k=10)
- Monta prompt com contexto recuperado
- Usa LLM para gerar resposta baseada apenas no contexto
- Implementado com **LCEL** (LangChain Expression Language)

### Chat (src/chat.py)
- Interface CLI interativa
- Loop de perguntas e respostas
- Comandos especiais: `sair`, `exit`, `quit`, `limpar`, `clear`
- FormataÃ§Ã£o colorida no terminal

### Prompt Template
O sistema usa um prompt rigoroso que:
- Instrui a LLM a responder **apenas** com base no contexto
- Fornece exemplos de perguntas fora do escopo
- Define mensagem padrÃ£o para respostas nÃ£o encontradas

---

## ğŸ”‘ Obtendo API Keys

### Google Gemini (GrÃ¡tis)
1. Acesse https://aistudio.google.com/app/apikey
2. FaÃ§a login com sua conta Google
3. Clique em "Create API Key"
4. Copie a chave gerada

### OpenAI (Pago)
1. Acesse https://platform.openai.com/api-keys
2. FaÃ§a login ou crie uma conta
3. Clique em "Create new secret key"
4. Copie a chave gerada

---

## ğŸ› Troubleshooting

### Erro: "Quota exceeded" (Gemini)
- A API gratuita do Gemini tem limites diÃ¡rios
- SoluÃ§Ã£o 1: Aguarde o reset da cota (24 horas)
- SoluÃ§Ã£o 2: Crie uma nova API key
- SoluÃ§Ã£o 3: Use modelo `text-embedding-004` no `.env`
- SoluÃ§Ã£o 4: Configure uma API key da OpenAI

### Erro: "Connection refused" (PostgreSQL)
- Verifique se o Docker estÃ¡ rodando: `docker compose ps`
- Reinicie o banco: `docker compose restart postgres`
- Aguarde alguns segundos para inicializaÃ§Ã£o completa

### Erro: "Collection not found"
- Execute a ingestÃ£o primeiro: `python src/ingest.py`

### Erro: "No API key configured"
- Verifique se o arquivo `.env` existe e estÃ¡ configurado
- Certifique-se de ter adicionado `GOOGLE_API_KEY` ou `OPENAI_API_KEY`

---

## ğŸ“š Requisitos do Desafio

- âœ… IngestÃ£o de PDF com chunks de 1000 caracteres e overlap de 150
- âœ… Armazenamento em PostgreSQL com pgVector
- âœ… Busca dos top 10 documentos mais relevantes (k=10)
- âœ… Respostas baseadas exclusivamente no contexto
- âœ… Mensagem padrÃ£o para perguntas fora do escopo
- âœ… Interface CLI interativa
- âœ… Suporte para OpenAI e Google Gemini
- âœ… Docker Compose para banco de dados
- âœ… DocumentaÃ§Ã£o completa

---

## ğŸ‘¨â€ğŸ’» Autor

Desenvolvido como parte do desafio do MBA em Engenharia de Software com IA - Full Cycle

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© parte de um desafio educacional.
